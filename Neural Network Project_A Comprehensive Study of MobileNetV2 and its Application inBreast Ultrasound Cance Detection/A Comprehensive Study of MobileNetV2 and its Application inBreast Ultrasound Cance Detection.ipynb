{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gRT99VxcOrZXquFL69DVtkJ25N-0rV2W","timestamp":1765266235810},{"file_id":"1BASYGnHDK2eJFqhh3oK4JEk5ktZgXD1D","timestamp":1760263642642}],"gpuType":"T4","authorship_tag":"ABX9TyMrKxTP6DZuzHEDvYJ4VQ/i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **# ğŸ§± Cellâ€“0: Colab Setup (TF, utils)**"],"metadata":{"id":"LvxnyjuMlzdv"}},{"cell_type":"code","source":["# ===== Cell 0: Base setup =====\n","!pip install -q tensorflow==2.15.0 scikit-learn matplotlib flask flask-cors pyngrok -U\n","\n","import os, json, random, warnings, glob, io, time\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n","\n","print(tf.__version__)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Sivid3dlUJK","executionInfo":{"status":"ok","timestamp":1760275315032,"user_tz":-360,"elapsed":11290,"user":{"displayName":"Md. Shakib Ahamed","userId":"08355253979928685150"}},"outputId":"3b2865e8-d33e-43b1-e5b9-0dbc58153b70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.15.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.15.0\u001b[0m\u001b[31m\n","\u001b[0m2.19.0\n"]}]},{"cell_type":"markdown","source":["# **ğŸ—‚ï¸ Cellâ€“à§§: Drive  + paths**"],"metadata":{"id":"8it8d0Xzl9wB"}},{"cell_type":"code","source":["# ===== Cell 1: Drive & paths =====\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# EDIT THESE to your paths\n","BUSI_DIR = \"/content/drive/MyDrive/CSE-51/8Th/Capstone/Alternative data/Breast Ultra Image/Dataset_BUSI_with_GT\"\n","OUT_DIR  = \"/content/drive/MyDrive/CSE-51/8Th/Capstone/Breast_Models\"\n","\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","CLASSES = [\"benign\", \"malignant\", \"normal\"]  # fixed order (stable API)\n","class_to_idx = {c:i for i,c in enumerate(CLASSES)}\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","\n","print(\"BUSI_DIR:\", BUSI_DIR)\n","print(\"OUT_DIR :\", OUT_DIR)\n","print(\"Classes :\", CLASSES)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5MbffV_lWfu","executionInfo":{"status":"ok","timestamp":1760275375526,"user_tz":-360,"elapsed":1794,"user":{"displayName":"Md. Shakib Ahamed","userId":"08355253979928685150"}},"outputId":"ee800771-0103-4839-c60e-1dde4a383cd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","BUSI_DIR: /content/drive/MyDrive/CSE-51/8Th/Capstone/Alternative data/Breast Ultra Image/Dataset_BUSI_with_GT\n","OUT_DIR : /content/drive/MyDrive/CSE-51/8Th/Capstone/Breast_Models\n","Classes : ['benign', 'malignant', 'normal']\n"]}]},{"cell_type":"markdown","source":["\n","# **ğŸ“¥ Cell 2: Data load gather & split + tf.data**\n","\n","\n"],"metadata":{"id":"9_87He0ImBk0"}},{"cell_type":"code","source":["# ===== Cell 2: Gather & split =====\n","paths, labels = [], []\n","for cls in CLASSES:\n","    cdir = os.path.join(BUSI_DIR, cls)\n","    imgs = sorted(glob.glob(os.path.join(cdir, \"*.png\"))) + \\\n","           sorted(glob.glob(os.path.join(cdir, \"*.jpg\"))) + \\\n","           sorted(glob.glob(os.path.join(cdir, \"*.jpeg\")))\n","    imgs = [p for p in imgs if not p.lower().endswith(\"_mask.png\")]\n","    paths.extend(imgs)\n","    labels.extend([cls]*len(imgs))\n","\n","assert len(paths) > 0, \"No images found. Check BUSI_DIR.\"\n","y = np.array([class_to_idx[l] for l in labels])\n","\n","for c in CLASSES:\n","    print(f\"{c}: {sum(1 for L in labels if L==c)}\")\n","\n","with open(os.path.join(OUT_DIR, \"labels.json\"), \"w\") as f:\n","    json.dump({str(k):v for k,v in idx_to_class.items()}, f, indent=2)\n","\n","X_temp, X_test, y_temp, y_test = train_test_split(paths, y, test_size=0.15, stratify=y, random_state=SEED)\n","X_train, X_val,  y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, stratify=y_temp, random_state=SEED)\n","print(f\"Split â†’ train={len(X_train)} | val={len(X_val)} | test={len(X_test)}\")\n","\n","IMG_SIZE   = (224, 224)\n","BATCH_SIZE = 32\n","\n","@tf.function\n","def load_image(path, label):\n","    img = tf.io.read_file(path)\n","    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n","    img = tf.image.resize(img, IMG_SIZE)\n","    img = tf.cast(img, tf.float32) / 255.0\n","    return img, label\n","\n","aug = keras.Sequential([\n","    layers.RandomFlip(\"horizontal\"),\n","    layers.RandomRotation(0.05),\n","    layers.RandomZoom(0.1),\n","    layers.RandomContrast(0.1),\n","], name=\"augment\")\n","\n","def build_ds(X, y, training):\n","    ds = tf.data.Dataset.from_tensor_slices((X, y))\n","    ds = ds.shuffle(len(X), seed=SEED) if training else ds\n","    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n","    if training:\n","        ds = ds.map(lambda a,b: (aug(a, training=True), b), num_parallel_calls=tf.data.AUTOTUNE)\n","    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","    return ds\n","\n","ds_train = build_ds(X_train, y_train, training=True)\n","ds_val   = build_ds(X_val,   y_val,   training=False)\n","ds_test  = build_ds(X_test,  y_test,  training=False)\n","\n","cnt = Counter(y_train)\n","total = sum(cnt.values())\n","class_weight = {i: total/(len(CLASSES)*cnt.get(i,1)) for i in range(len(CLASSES))}\n","print(\"Class weights:\", class_weight)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_5gEuPhklrQ0","executionInfo":{"status":"ok","timestamp":1760275398713,"user_tz":-360,"elapsed":13683,"user":{"displayName":"Md. Shakib Ahamed","userId":"08355253979928685150"}},"outputId":"3d784556-e942-4742-fcd3-230e3d148a6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["benign: 454\n","malignant: 211\n","normal: 133\n","Split â†’ train=558 | val=120 | test=120\n","Class weights: {0: 0.5849056603773585, 1: 1.2653061224489797, 2: 2.0}\n"]}]},{"cell_type":"markdown","source":["# **ğŸ§ ** Cell 3 : Model Traning"],"metadata":{"id":"jctEbjz5mJxN"}},{"cell_type":"code","source":["# ===== Cell 3: Train & fine-tune =====\n","base = tf.keras.applications.MobileNetV2(include_top=False, weights=\"imagenet\",\n","                                         input_shape=IMG_SIZE+(3,))\n","base.trainable = False\n","\n","inputs = keras.Input(shape=IMG_SIZE+(3,))\n","x = base(inputs, training=False)\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.3)(x)\n","outputs = layers.Dense(len(CLASSES), activation=\"softmax\")(x)\n","model = keras.Model(inputs, outputs)\n","\n","model.compile(optimizer=keras.optimizers.Adam(1e-3),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","ckpt = os.path.join(OUT_DIR, \"busi_mobilenetv2_best.keras\")\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(ckpt, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n","    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=6, restore_best_weights=True, verbose=1),\n","    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n","]\n","\n","print(\"Training (frozen)â€¦\")\n","model.fit(ds_train, validation_data=ds_val, epochs=20,\n","          class_weight=class_weight, callbacks=callbacks, verbose=1)\n","\n","base.trainable = True\n","for layer in base.layers[:-30]:\n","    layer.trainable = False\n","\n","model.compile(optimizer=keras.optimizers.Adam(1e-5),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","print(\"Fine-tuning (top layers)â€¦\")\n","model.fit(ds_train, validation_data=ds_val, epochs=10,\n","          class_weight=class_weight, callbacks=callbacks, verbose=1)\n","\n","best_model = keras.models.load_model(ckpt)\n","\n","# Evaluate\n","test_loss, test_acc = best_model.evaluate(ds_test, verbose=0)\n","print(f\"Test accuracy: {test_acc:.3f} | loss: {test_loss:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erMxWxdolwpV","executionInfo":{"status":"ok","timestamp":1760275931305,"user_tz":-360,"elapsed":525669,"user":{"displayName":"Md. Shakib Ahamed","userId":"08355253979928685150"}},"outputId":"b490b1e5-c43e-402b-baf4-e57996547274"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Training (frozen)â€¦\n","Epoch 1/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.4275 - loss: 1.4247\n","Epoch 1: val_accuracy improved from -inf to 0.52500, saving model to /content/drive/MyDrive/CSE-51/8Th/Capstone/Breast_Models/busi_mobilenetv2_best.keras\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 13s/step - accuracy: 0.4261 - loss: 1.4200 - val_accuracy: 0.5250 - val_loss: 0.9914 - learning_rate: 0.0010\n","Epoch 2/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.5032 - loss: 1.0357\n","Epoch 2: val_accuracy improved from 0.52500 to 0.55833, saving model to /content/drive/MyDrive/CSE-51/8Th/Capstone/Breast_Models/busi_mobilenetv2_best.keras\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 615ms/step - accuracy: 0.5041 - loss: 1.0345 - val_accuracy: 0.5583 - val_loss: 0.9552 - learning_rate: 0.0010\n","Epoch 3/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.5654 - loss: 0.8641\n","Epoch 3: val_accuracy improved from 0.55833 to 0.61667, saving model to /content/drive/MyDrive/CSE-51/8Th/Capstone/Breast_Models/busi_mobilenetv2_best.keras\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 670ms/step - accuracy: 0.5671 - loss: 0.8634 - val_accuracy: 0.6167 - val_loss: 0.8705 - learning_rate: 0.0010\n","Epoch 4/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.5886 - loss: 0.8190\n","Epoch 4: val_accuracy improved from 0.61667 to 0.66667, saving model to /content/drive/MyDrive/CSE-51/8Th/Capstone/Breast_Models/busi_mobilenetv2_best.keras\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 652ms/step - accuracy: 0.5900 - loss: 0.8189 - val_accuracy: 0.6667 - val_loss: 0.7541 - learning_rate: 0.0010\n","Epoch 5/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.6734 - loss: 0.7508\n","Epoch 5: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 598ms/step - accuracy: 0.6725 - loss: 0.7507 - val_accuracy: 0.5500 - val_loss: 0.9615 - learning_rate: 0.0010\n","Epoch 6/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.6543 - loss: 0.7723\n","Epoch 6: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 579ms/step - accuracy: 0.6541 - loss: 0.7717 - val_accuracy: 0.6083 - val_loss: 0.8383 - learning_rate: 0.0010\n","Epoch 7/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.6762 - loss: 0.6800\n","Epoch 7: val_accuracy did not improve from 0.66667\n","\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 561ms/step - accuracy: 0.6765 - loss: 0.6802 - val_accuracy: 0.6500 - val_loss: 0.8056 - learning_rate: 0.0010\n","Epoch 8/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.7115 - loss: 0.6375\n","Epoch 8: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 642ms/step - accuracy: 0.7101 - loss: 0.6400 - val_accuracy: 0.6333 - val_loss: 0.8018 - learning_rate: 5.0000e-04\n","Epoch 9/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.7092 - loss: 0.6665\n","Epoch 9: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 598ms/step - accuracy: 0.7080 - loss: 0.6666 - val_accuracy: 0.6583 - val_loss: 0.8151 - learning_rate: 5.0000e-04\n","Epoch 10/20\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.6943 - loss: 0.6422\n","Epoch 10: val_accuracy did not improve from 0.66667\n","\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 602ms/step - accuracy: 0.6950 - loss: 0.6425 - val_accuracy: 0.6500 - val_loss: 0.7681 - learning_rate: 5.0000e-04\n","Epoch 10: early stopping\n","Restoring model weights from the end of the best epoch: 4.\n","Fine-tuning (top layers)â€¦\n","Epoch 1/10\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.5926 - loss: 2.0334\n","Epoch 1: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5935 - loss: 2.0277 - val_accuracy: 0.6583 - val_loss: 0.7809 - learning_rate: 1.0000e-05\n","Epoch 2/10\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - accuracy: 0.6669 - loss: 1.5533\n","Epoch 2: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 549ms/step - accuracy: 0.6648 - loss: 1.5623 - val_accuracy: 0.6333 - val_loss: 0.8028 - learning_rate: 1.0000e-05\n","Epoch 3/10\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.6391 - loss: 1.4943\n","Epoch 3: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 558ms/step - accuracy: 0.6394 - loss: 1.4944 - val_accuracy: 0.6500 - val_loss: 0.8200 - learning_rate: 1.0000e-05\n","Epoch 4/10\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.6808 - loss: 1.2352\n","Epoch 4: val_accuracy did not improve from 0.66667\n","\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 612ms/step - accuracy: 0.6801 - loss: 1.2352 - val_accuracy: 0.6500 - val_loss: 0.8277 - learning_rate: 1.0000e-05\n","Epoch 5/10\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.6671 - loss: 1.1787\n","Epoch 5: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 640ms/step - accuracy: 0.6678 - loss: 1.1715 - val_accuracy: 0.6500 - val_loss: 0.8318 - learning_rate: 5.0000e-06\n","Epoch 6/10\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.6622 - loss: 1.1110\n","Epoch 6: val_accuracy did not improve from 0.66667\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 623ms/step - accuracy: 0.6635 - loss: 1.1053 - val_accuracy: 0.6417 - val_loss: 0.8345 - learning_rate: 5.0000e-06\n","Epoch 7/10\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.6983 - loss: 0.8654\n","Epoch 7: val_accuracy did not improve from 0.66667\n","\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n","\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 534ms/step - accuracy: 0.6969 - loss: 0.8695 - val_accuracy: 0.6417 - val_loss: 0.8376 - learning_rate: 5.0000e-06\n","Epoch 7: early stopping\n","Restoring model weights from the end of the best epoch: 1.\n","Test accuracy: 0.700 | loss: 0.720\n"]}]}]}