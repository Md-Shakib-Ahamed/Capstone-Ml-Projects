{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1LI1mE7nzX2WtaEnzJWXNrDAfcYYPQ-zT","authorship_tag":"ABX9TyPUkm6yTW/gpdr+Wd1hv5ax"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljozuCuWyekG","executionInfo":{"status":"ok","timestamp":1760954892462,"user_tz":-360,"elapsed":233135,"user":{"displayName":"Sadhin Ahamad","userId":"14246543205241700467"}},"outputId":"dc74d2a5-6000-4da0-a0c1-e34dca1a0a9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: scikit-learn 1.4.2\n","Uninstalling scikit-learn-1.4.2:\n","  Successfully uninstalled scikit-learn-1.4.2\n","\u001b[33mWARNING: Skipping umap-learn as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping cuml-cu12 as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mCollecting scikit-learn==1.4.2\n","  Using cached scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: tensorflow==2.18.0 in /usr/local/lib/python3.12/dist-packages (2.18.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.7)\n","Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.12/dist-packages (0.16.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (3.6.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (1.75.1)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (3.15.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.18.0) (0.4.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-hub) (2.18.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.18.0) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.9)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0) (0.1.2)\n","Using cached scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n","Installing collected packages: scikit-learn\n","Successfully installed scikit-learn-1.4.2\n","âœ… scikit-learn: 1.4.2\n","âœ… TensorFlow: 2.18.0\n","âš™ï¸ Mounting Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","âœ… Drive mounted.\n","ðŸ§¾ Total images: 2644 | mask coverage â‰ˆ 45.5%\n","Split â†’ train=1850 | val=397 | test=397\n"]}],"source":["# ============================================================\n","# Breast Ultrasound: Gatekeeper + Mask-aware 3-Class Classifier\n","# Dataset: BUSI (benign, malignant, normal)\n","# ============================================================\n","# Remove conflicting builds\n","!pip uninstall -y scikit-learn umap-learn cuml-cu12 || true\n","\n","# Install compatible versions\n","!pip install -U \"scikit-learn==1.4.2\" \"tensorflow==2.18.0\" opencv-python tqdm matplotlib tensorflow-hub\n","\n","# Verify\n","import sklearn, tensorflow as tf\n","print(\"âœ… scikit-learn:\", sklearn.__version__)\n","print(\"âœ… TensorFlow:\", tf.__version__)\n","\n","import os, glob, json, random, warnings\n","warnings.filterwarnings(\"ignore\")\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","import cv2\n","from tqdm import tqdm\n","from google.colab import drive, files\n","import tensorflow_hub as hub\n","\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n","\n","# -------------------------\n","# 0) Mount Drive & set paths\n","# -------------------------\n","print(\"âš™ï¸ Mounting Drive...\")\n","drive.mount('/content/drive')\n","print(\"âœ… Drive mounted.\")\n","\n","DATA_ROOTS = [\n","  \"/content/drive/MyDrive/Capstone/Alternative data/Breast Ultra Image/Dataset_BUSI_with_GT\"\n","]\n","OUT_DIR = \"/content/drive/MyDrive/Capstone/Breast_Models_API\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","IMG_SIZE   = (224, 224)\n","BATCH_SIZE = 32\n","CLASSES    = [\"normal\", \"benign\", \"malignant\"]\n","class_to_idx = {c:i for i,c in enumerate(CLASSES)}\n","idx_to_class = {i:c for c,i in class_to_idx.items()}\n","\n","# -------------------------\n","# 1) Dataset collection\n","# -------------------------\n","def is_mask_path(p):\n","    name = os.path.basename(p).lower()\n","    return (\"mask\" in name) or name.endswith(\"_mask.png\") or name.endswith(\"_gt.png\")\n","\n","def collect_dataset(data_roots):\n","    paths, labels, mask_paths = [], [], []\n","    for root in data_roots:\n","        for cls in CLASSES:\n","            cdir = os.path.join(root, cls)\n","            if not os.path.isdir(cdir):\n","                continue\n","            imgs = []\n","            for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\"):\n","                imgs += glob.glob(os.path.join(cdir, ext))\n","            imgs = [p for p in imgs if not is_mask_path(p)]\n","            for p in imgs:\n","                stem = os.path.splitext(os.path.basename(p))[0].lower()\n","                folder = os.path.dirname(p)\n","                mask = \"\"\n","                for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\"):\n","                    for m in glob.glob(os.path.join(folder, ext)):\n","                        if \"mask\" in m.lower() and stem in m.lower():\n","                            mask = m\n","                            break\n","                paths.append(p)\n","                labels.append(class_to_idx[cls])\n","                mask_paths.append(mask)\n","    return np.array(paths), np.array(labels), np.array(mask_paths)\n","\n","paths, labels, mask_paths = collect_dataset(DATA_ROOTS)\n","assert len(paths)>0, \"âŒ No images found. Check DATA_ROOTS or class folder names!\"\n","print(f\"ðŸ§¾ Total images: {len(paths)} | mask coverage â‰ˆ {np.mean(mask_paths!='')*100:.1f}%\")\n","\n","# -------------------------\n","# 2) Split dataset\n","# -------------------------\n","X_temp, X_test, y_temp, y_test, m_temp, m_test = train_test_split(\n","    paths, labels, mask_paths, test_size=0.15, stratify=labels, random_state=SEED\n",")\n","X_train, X_val, y_train, y_val, m_train, m_val = train_test_split(\n","    X_temp, y_temp, m_temp, test_size=0.1765, stratify=y_temp, random_state=SEED\n",")\n","print(f\"Split â†’ train={len(X_train)} | val={len(X_val)} | test={len(X_test)}\")\n","\n","# -------------------------\n","# 3) Helper functions\n","# -------------------------\n","def load_image_bgr(path):\n","    img = cv2.imread(path, cv2.IMREAD_COLOR)\n","    return img if img is not None else np.zeros((224,224,3), np.uint8)\n","\n","def load_mask(mask_path, base_img):\n","    if mask_path and os.path.exists(mask_path):\n","        m = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","        _, mb = cv2.threshold(m, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","        return (mb>0).astype(np.uint8)\n","    else:\n","        return np.zeros(base_img.shape[:2], np.uint8)\n","\n","def roi_from_mask(img_bgr, mask_bin):\n","    if mask_bin.sum()==0: return img_bgr\n","    ys, xs = np.where(mask_bin>0)\n","    y0, y1 = max(ys.min()-10,0), min(ys.max()+10, img_bgr.shape[0]-1)\n","    x0, x1 = max(xs.min()-10,0), min(xs.max()+10, img_bgr.shape[1]-1)\n","    return img_bgr[y0:y1+1, x0:x1+1]\n","\n","def to_tensor(img_bgr, size=IMG_SIZE):\n","    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n","    img_rgb = cv2.resize(img_rgb, size, interpolation=cv2.INTER_AREA)\n","    return img_rgb.astype(np.float32)/255.0\n","\n","# -------------------------\n","# 4) Dataset generator\n","# -------------------------\n","def gen_dataset(X, y, M, training=True):\n","    idxs = np.arange(len(X))\n","    if training: np.random.shuffle(idxs)\n","    for i in idxs:\n","        img = load_image_bgr(X[i])\n","        mask = load_mask(M[i], img)\n","        roi = roi_from_mask(img, mask)\n","        arr = to_tensor(roi)\n","        if training:\n","            if random.random()<0.5: arr = arr[:, ::-1, :]\n","            if random.random()<0.2: arr = np.clip(arr + np.random.uniform(-0.08,0.08), 0,1)\n","        yield arr, y[i]\n","\n","sig = (tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.float32),\n","       tf.TensorSpec(shape=(), dtype=tf.int32))\n","\n","def build_tfds(X, y, M, training):\n","    ds = tf.data.Dataset.from_generator(lambda: gen_dataset(X,y,M,training), output_signature=sig)\n","    if training: ds = ds.shuffle(1024)\n","    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","    return ds\n","\n","ds_train = build_tfds(X_train, y_train, m_train, True)\n","ds_val   = build_tfds(X_val,   y_val,   m_val,   False)\n","ds_test  = build_tfds(X_test,  y_test,  m_test,  False)\n","\n"]},{"cell_type":"code","source":["# -------------------------\n","# 5) Model: EfficientNetB3 (Auto-Fallback Safe)\n","# -------------------------\n","try:\n","    from tensorflow.keras.applications import EfficientNetB3\n","    base = EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=IMG_SIZE+(3,))\n","    print(\"âœ… Using native EfficientNetB3 from tf.keras.applications\")\n","except:\n","    print(\"âš ï¸ EfficientNetB3 not found, using TensorFlow Hub version instead.\")\n","    effnet_url = \"https://tfhub.dev/google/efficientnet/b3/feature-vector/1\"\n","    base = hub.KerasLayer(effnet_url, input_shape=IMG_SIZE+(3,), trainable=False)\n","\n","# Build classification head\n","if isinstance(base, keras.Model):\n","    x = base.output\n","else:\n","    inputs = keras.Input(shape=IMG_SIZE+(3,))\n","    x = base(inputs)\n","\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.4)(x)\n","outputs = layers.Dense(len(CLASSES), activation=\"softmax\")(x)\n","\n","if isinstance(base, keras.Model):\n","    model = keras.Model(inputs=base.input, outputs=outputs)\n","else:\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-3),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","ckpt = os.path.join(OUT_DIR, \"busi_effnetb3_best.keras\")\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(ckpt, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n","    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=6, restore_best_weights=True, verbose=1),\n","    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n","]\n","\n","print(\"ðŸ§  Training (frozen backbone)â€¦\")\n","model.fit(ds_train, validation_data=ds_val, epochs=20, callbacks=callbacks, verbose=1)\n","\n","# Fine-tune\n","if hasattr(base, \"trainable\"):\n","    base.trainable = True\n","    for layer in base.layers[:-40]:\n","        layer.trainable = False\n","\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(1e-5),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"]\n","    )\n","\n","    print(\"ðŸ§  Fine-tuningâ€¦\")\n","    model.fit(ds_train, validation_data=ds_val, epochs=10, callbacks=callbacks, verbose=1)\n","\n","best_model = keras.models.load_model(ckpt, custom_objects={\"KerasLayer\": hub.KerasLayer})\n","test_loss, test_acc = best_model.evaluate(ds_test, verbose=0)\n","print(f\"âœ… Test accuracy: {test_acc:.3f} | loss: {test_loss:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ou2HwxACynzG","outputId":"2503a41a-5fa6-4e71-b957-74a300f8fbaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n","\u001b[1m43941136/43941136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","âœ… Using native EfficientNetB3 from tf.keras.applications\n","ðŸ§  Training (frozen backbone)â€¦\n","Epoch 1/20\n","     58/Unknown \u001b[1m1864s\u001b[0m 19s/step - accuracy: 0.7371 - loss: 0.6011\n","Epoch 1: val_accuracy improved from -inf to 0.27204, saving model to /content/drive/MyDrive/Capstone/Breast_Models_API/busi_effnetb3_best.keras\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2100s\u001b[0m 23s/step - accuracy: 0.7387 - loss: 0.5988 - val_accuracy: 0.2720 - val_loss: 2.4821 - learning_rate: 0.0010\n","Epoch 2/20\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - accuracy: 0.8773 - loss: 0.3013 \n","Epoch 2: val_accuracy improved from 0.27204 to 0.52393, saving model to /content/drive/MyDrive/Capstone/Breast_Models_API/busi_effnetb3_best.keras\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1135s\u001b[0m 19s/step - accuracy: 0.8775 - loss: 0.3010 - val_accuracy: 0.5239 - val_loss: 2.4202 - learning_rate: 0.0010\n","Epoch 3/20\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - accuracy: 0.9147 - loss: 0.2070 \n","Epoch 3: val_accuracy did not improve from 0.52393\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1139s\u001b[0m 19s/step - accuracy: 0.9147 - loss: 0.2071 - val_accuracy: 0.3904 - val_loss: 4.6944 - learning_rate: 0.0010\n","Epoch 4/20\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - accuracy: 0.9367 - loss: 0.1586 \n","Epoch 4: val_accuracy did not improve from 0.52393\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 19s/step - accuracy: 0.9367 - loss: 0.1587 - val_accuracy: 0.3451 - val_loss: 6.6880 - learning_rate: 0.0010\n","Epoch 5/20\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - accuracy: 0.9386 - loss: 0.1572 \n","Epoch 5: val_accuracy did not improve from 0.52393\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m58/58\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1135s\u001b[0m 19s/step - accuracy: 0.9386 - loss: 0.1574 - val_accuracy: 0.3501 - val_loss: 8.9456 - learning_rate: 0.0010\n","Epoch 6/20\n","\u001b[1m20/58\u001b[0m \u001b[32mâ”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m11:33\u001b[0m 18s/step - accuracy: 0.9484 - loss: 0.1316"]}]},{"cell_type":"code","metadata":{"id":"83c98986"},"source":["# ============================================================\n","# Recreate and save the model\n","# ============================================================\n","\n","# Recreate the model architecture\n","def build_model(base_model_type):\n","    if base_model_type == \"keras\":\n","        from tensorflow.keras.applications import EfficientNetB3\n","        # Use input_shape for Keras Applications model\n","        base = EfficientNetB3(include_top=False, weights=None, input_shape=IMG_SIZE+(3,)) # No weights here\n","        print(\"âœ… Using native EfficientNetB3 from tf.keras.applications\")\n","        x = base.output\n","        inputs = base.input # Define inputs from base model\n","    else: # Use TensorFlow Hub\n","        effnet_url = \"https://tfhub.dev/google/efficientnet/b3/feature-vector/1\"\n","        # Use input_shape for KerasLayer\n","        base = hub.KerasLayer(effnet_url, input_shape=IMG_SIZE+(3,), trainable=False)\n","        print(\"âš ï¸ EfficientNetB3 not found, using TensorFlow Hub version instead.\")\n","        inputs = keras.Input(shape=IMG_SIZE+(3,))\n","        x = base(inputs)\n","\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dropout(0.4)(x)\n","    outputs = layers.Dense(len(CLASSES), activation=\"softmax\")(x)\n","\n","    # Ensure inputs and outputs are correctly defined for the model\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","# Determine which base model was used during training\n","try:\n","    from tensorflow.keras.applications import EfficientNetB3\n","    # Check if the base model in the original model is from Keras Applications\n","    # This is a heuristic, a more robust way would be to check the type of `base`\n","    # in the original model definition if possible. For now, we assume if\n","    # EfficientNetB3 from keras.applications is available, that's what was used.\n","    model_type = \"keras\"\n","    print(\"Determined model type: Keras Applications\")\n","    # A more robust check could involve inspecting the layers of the trained model\n","    # For example: any(isinstance(layer, EfficientNetB3) for layer in best_model.layers)\n","except:\n","    model_type = \"hub\"\n","    print(\"Determined model type: TensorFlow Hub\")\n","    # Similarly, check for KerasLayer from hub\n","    # For example: any(isinstance(layer, hub.KerasLayer) for layer in best_model.layers)\n","\n","\n","print(f\"Attempting to build model with base type: {model_type}\")\n","# Build a new model instance with the determined base type\n","recreated_model = build_model(model_type)\n","\n","# Load the best weights from the checkpoint\n","# Use by_name=True to handle potential layer name differences if model structure is slightly different\n","try:\n","    recreated_model.load_weights(ckpt) # Removed by_name=True\n","    print(\"âœ… Weights loaded into recreated model.\")\n","except Exception as e:\n","    print(f\"âŒ Error loading weights: {e}\")\n","\n","\n","# Save the model as a standard TensorFlow SavedModel\n","export_dir_recreated = os.path.join(OUT_DIR, \"api_savedmodel_effnetb3_recreated\")\n","try:\n","    tf.saved_model.save(recreated_model, export_dir_recreated)\n","    print(\"ðŸ’¾ SavedModel exported (recreated model) â†’\", export_dir_recreated)\n","\n","    # âœ… Save label mapping (for app + API) - This part is already correct\n","    labels_path = os.path.join(OUT_DIR, \"labels_3class.json\")\n","    with open(labels_path, \"w\") as f:\n","        json.dump(idx_to_class, f, indent=2)\n","    print(\"ðŸ“ Labels saved â†’\", labels_path)\n","\n","    # âœ… Convert SavedModel â†’ TFLite (dynamic-range quantization) - Use the newly saved model\n","    tflite_path_recreated = os.path.join(OUT_DIR, \"busi_effnetb3_recreated.tflite\")\n","    converter_recreated = tf.lite.TFLiteConverter.from_saved_model(export_dir_recreated)\n","    converter_recreated.optimizations = [tf.lite.Optimize.DEFAULT]\n","    tflite_model_recreated = converter_recreated.convert()\n","\n","    with open(tflite_path_recreated, \"wb\") as f:\n","        f.write(tflite_model_recreated)\n","    print(\"ðŸ“± TFLite exported (recreated model) â†’\", tflite_path_recreated)\n","\n","except TypeError as e:\n","    print(f\"âŒ Still encountered TypeError during SavedModel export: {e}\")\n","    print(\"This might be an issue with the TensorFlow version or specific layer compatibility with SavedModel.\")\n","    print(\"You can still use the loaded 'best_model' for predictions within this notebook.\")\n","\n","\n","# You can still use the best_model loaded previously for testing\n","# -------------------------\n","# 7) Multi-image test upload - Keep this part as it uses the loaded best_model\n","# -------------------------\n","def preprocess_single_image(img_path, img_size=IMG_SIZE):\n","    img = cv2.imread(img_path)\n","    if img is None: return None\n","    arr = to_tensor(img, img_size)\n","    return np.expand_dims(arr, axis=0)\n","\n","def predict_multiple_images(model, img_paths):\n","    all_probs = []\n","    for path in img_paths:\n","        x = preprocess_single_image(path)\n","        if x is None: continue\n","        # Use verbose=0 to suppress progress bar for cleaner output\n","        prob = model.predict(x, verbose=0)[0]\n","        all_probs.append(prob)\n","        top = np.argmax(prob)\n","        print(f\"ðŸ“· {os.path.basename(path)} â†’ {idx_to_class[top]} ({prob[top]:.2f})\")\n","    if all_probs: # Check if any valid images were processed\n","      avg = np.mean(all_probs, axis=0)\n","      return idx_to_class[np.argmax(avg)], float(np.max(avg))\n","    else:\n","      return \"N/A\", 0.0\n","\n","\n","print(\"\\nðŸŸ¦ Upload 1â€“N BUSI images for testing:\")\n","# Ensure the files.upload() is only called once if you run this cell multiple times\n","if 'uploaded' not in locals(): # Check if uploaded variable exists\n","    uploaded = files.upload()\n","\n","if uploaded:\n","    # Use the 'best_model' which was successfully loaded with custom_objects\n","    final_label, conf = predict_multiple_images(best_model, list(uploaded.keys()))\n","    print(f\"\\nðŸ” Final aggregated prediction â†’ {final_label.upper()} (confidence {conf:.2f})\")\n","else:\n","    print(\"No files uploaded.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import os, json, tensorflow_hub as hub\n","\n","# Paths\n","OUT_DIR = \"/content/drive/MyDrive/Capstone/Breast_Models_API\"\n","keras_model_path = os.path.join(OUT_DIR, \"busi_effnetb3_best.keras\")\n","export_dir = os.path.join(OUT_DIR, \"api_savedmodel_effnetb3_float32\")\n","tflite_path = os.path.join(OUT_DIR, \"busi_effnetb3_float32.tflite\")\n","\n","# âœ… 1. Load model (supports TF-Hub layers)\n","model = tf.keras.models.load_model(\n","    keras_model_path, custom_objects={\"KerasLayer\": hub.KerasLayer}\n",")\n","print(\"âœ… Model loaded successfully.\")\n","\n","# âœ… 2. Rebuild clean exportable model\n","inputs = tf.keras.Input(shape=model.input_shape[1:], name=\"input\")\n","outputs = model(inputs, training=False)\n","exportable_model = tf.keras.Model(inputs, outputs)\n","print(\"ðŸ§© Rebuilt clean model for export.\")\n","\n","# âœ… 3. Export as TensorFlow SavedModel (correct for Keras 3)\n","exportable_model.export(export_dir)\n","print(\"ðŸ’¾ SavedModel exported safely â†’\", export_dir)\n","\n","# âœ… 4. Convert to TFLite (float32 precision, no quantization)\n","converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n","converter._experimental_lower_tensor_list_ops = False\n","tflite_model = converter.convert()\n","\n","# âœ… 5. Save .tflite file\n","with open(tflite_path, \"wb\") as f:\n","    f.write(tflite_model)\n","print(\"ðŸ“± Float32 TFLite exported â†’\", tflite_path)\n","\n","# âœ… 6. Save label mapping\n","labels_path = os.path.join(OUT_DIR, \"labels_3class.json\")\n","idx_to_class = {0: \"normal\", 1: \"benign\", 2: \"malignant\"}\n","with open(labels_path, \"w\") as f:\n","    json.dump(idx_to_class, f, indent=2)\n","print(\"ðŸ“ Labels saved â†’\", labels_path)\n"],"metadata":{"id":"so2ArlFasgRO"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fb64dbeb"},"source":["# ============================================================\n","# ðŸ“Š MODEL PERFORMANCE VISUALIZATION (SAFE VERSION)\n","# ============================================================\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n","\n","# 1ï¸âƒ£ TRAINING CURVES (if available)\n","try:\n","    history = model.history.history if hasattr(model, 'history') else None\n","except NameError:\n","    history = None  # model not in scope\n","\n","if history:\n","    plt.figure(figsize=(10,4))\n","    plt.subplot(1,2,1)\n","    plt.plot(history['accuracy'], label='Train Accuracy')\n","    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n","    plt.title('Training & Validation Accuracy')\n","    plt.xlabel('Epochs'); plt.ylabel('Accuracy'); plt.legend()\n","\n","    plt.subplot(1,2,2)\n","    plt.plot(history['loss'], label='Train Loss')\n","    plt.plot(history['val_loss'], label='Validation Loss')\n","    plt.title('Training & Validation Loss')\n","    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend()\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"âš ï¸ No training history found â€” skipping curve plots.\")\n","\n","# 2ï¸âƒ£ CONFUSION MATRIX\n","y_true, y_pred = [], []\n","for X_batch, y_batch in ds_test:\n","    preds = best_model.predict(X_batch, verbose=0)\n","    y_true.extend(y_batch.numpy())\n","    y_pred.extend(np.argmax(preds, axis=1))\n","\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(6,5))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=CLASSES, yticklabels=CLASSES)\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# 3ï¸âƒ£ CLASSIFICATION REPORT\n","report = classification_report(y_true, y_pred, target_names=CLASSES, output_dict=True)\n","report_df = pd.DataFrame(report).transpose()\n","print(\"\\nðŸ“„ Classification Report:\")\n","print(report_df.round(3))\n","\n","plt.figure(figsize=(8,4))\n","sns.barplot(x=report_df.index[:-3], y=report_df['f1-score'][:-3])\n","plt.title(\"F1-score per Class\")\n","plt.ylabel(\"F1-Score\")\n","plt.xticks(rotation=30)\n","plt.show()\n","\n","# 4ï¸âƒ£ ROC & AUC Curves for Multi-Class\n","y_true_bin = tf.keras.utils.to_categorical(y_true, num_classes=len(CLASSES))\n","y_pred_prob = np.array([\n","    best_model.predict(X, verbose=0) for X, _ in ds_test\n","]).reshape(-1, len(CLASSES))\n","\n","plt.figure(figsize=(7,6))\n","for i, cls in enumerate(CLASSES):\n","    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n","    roc_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, lw=2, label=f'{cls} (AUC={roc_auc:.2f})')\n","plt.plot([0,1], [0,1], 'k--', lw=1)\n","plt.title('ROC Curves for Each Class')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc='lower right')\n","plt.show()\n","\n","# 5ï¸âƒ£ PRECISION-RECALL Curves\n","plt.figure(figsize=(7,6))\n","for i, cls in enumerate(CLASSES):\n","    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n","    plt.plot(recall, precision, lw=2, label=f'{cls}')\n","plt.title('Precision-Recall Curve')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.legend()\n","plt.show()\n"],"execution_count":null,"outputs":[]}]}